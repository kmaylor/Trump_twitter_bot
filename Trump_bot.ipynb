{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import pickle as p\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from numpy import arange, where, isin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys=p.load(open('tk.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "auth = OAuthHandler(twitter_keys['consumer_key'], twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token'], twitter_keys['access_secret'])\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_handled(cursor):\n",
    "    while True:\n",
    "        try:\n",
    "            yield cursor.next()\n",
    "        except tweepy.RateLimitError:\n",
    "            time.sleep(15 * 60)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold=[]\n",
    "with open('test.txt','w') as f:\n",
    "    json.dump([], f)\n",
    "for i,status in enumerate(limit_handled(tweepy.Cursor(api.user_timeline,'realDonaldTrump').items(1000))):\n",
    "    hold.append(status._json)\n",
    "    if i%100==0:\n",
    "        with open('test.txt','r') as f:\n",
    "            a=json.load(f)+hold\n",
    "        with open('test.txt','w') as f:\n",
    "            json.dump(a, f)\n",
    "        hold=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets=json.load(open('test.txt','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retweet_filter(tweet):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_links(tweet_words):\n",
    "    try:\n",
    "        cutoff=where([x=='https' for x in tweet_words])[0][0]\n",
    "        return tweet_words[:cutoff]\n",
    "    except IndexError:\n",
    "        return tweet_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_to_list(tweets):\n",
    "    tweet_words=[]\n",
    "    for tweet in tweets:\n",
    "        if tweet['text'][:2]!='RT':\n",
    "            tweet_words.extend(drop_links(re.findall(r\"[\\w']+|[.,!?;]\",tweet['text'])))\n",
    "    return tweet_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_words=tweets_to_list(trump_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_using_ngrams(n,words):\n",
    "    '''\n",
    "    Generate a sentence using the ngrams method. \n",
    "    \n",
    "    Params:\n",
    "    n: Words is broken into seqences of length n, n-1 words are then used to predict the next word.\n",
    "    words: A list of words that generated sentences will be based on.\n",
    "    '''\n",
    "    \n",
    "    if not n>1:raise ValueError(\"n must be at least 2\")\n",
    "        \n",
    "    ngrams=zip(*[words[i:] for i in arange(n)])\n",
    "    transitions=defaultdict(list)\n",
    "    starts=[]\n",
    "    \n",
    "    for ngram in ngrams:\n",
    "        if ngram[0] in ['.','!','?']:\n",
    "            starts.append(ngram[1:-1])\n",
    "        transitions[ngram[:-1]].append(ngram[-1])\n",
    "    \n",
    "    \n",
    "    current= random.choice(starts)\n",
    "    prev='.'\n",
    "    result=[*current]\n",
    "\n",
    "    while True:\n",
    "        next_word_candidates=transitions[(prev,*current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "        prev, current = current[0], current[1:]+(next_word,)\n",
    "        result.append(current[-1])\n",
    "        if current[-1] in ['.','!','?']: return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If we can do much better as a National Enquirer article .'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_using_ngrams(3,trump_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_using_nxmgrams(n,m,words):\n",
    "    '''\n",
    "    Generate a sentence using the ngrams method. \n",
    "    \n",
    "    Params:\n",
    "    n: Words is broken into seqences of length n, n-1 words are then used to predict the next word.\n",
    "    words: A list of words that generated sentences will be based on.\n",
    "    '''\n",
    "    \n",
    "    if not n>1:raise ValueError(\"n must be at least 2\")\n",
    "        \n",
    "    nxmgrams=zip(*[words[i:] for i in arange(n+m)])\n",
    "    transitions=defaultdict(list)\n",
    "    starts=[]\n",
    "    \n",
    "    for nxmgram in nxmgrams:\n",
    "        if nxmgram[0] in ['.','!','?']:\n",
    "            starts.append(nxmgram[1:-m])\n",
    "        transitions[nxmgram[:-m]].append(nxmgram[-m:])\n",
    "    \n",
    "    current= random.choice(starts)\n",
    "    prev='.'\n",
    "    result=[*current]\n",
    "    while True:\n",
    "        print(prev,current)\n",
    "        next_word_candidates=transitions[(prev,*current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "        prev = current[m-n]\n",
    "        if n-1-m==0:\n",
    "            current = (*next_word,)\n",
    "        else:\n",
    "            current =  current[m+1-n:]+(*next_word,)\n",
    "        for c in current[-m:]: result.append(c)\n",
    "        print(result)\n",
    "        if current[-1] in ['.','!','?']: return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". ('We', 'pledge')\n",
      "['We', 'pledge', 'our', 'solidarity']\n",
      "pledge ('our', 'solidarity')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France']\n",
      "solidarity ('with', 'France')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror']\n",
      "France ('against', 'terror')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It']\n",
      "terror ('.', 'It')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a']\n",
      "It ('was', 'a')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor']\n",
      "a ('great', 'honor')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome']\n",
      "honor ('to', 'welcome')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister']\n",
      "welcome ('Prime', 'Minister')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul']\n",
      "Minister ('Najib', 'Abdul')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of']\n",
      "Abdul ('Razak', 'of')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and']\n",
      "of ('Malaysia', 'and')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished']\n",
      "and ('his', 'distinguished')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to']\n",
      "distinguished ('delegation', 'to')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations']\n",
      "to ('th', 'Congratulations')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric']\n",
      "Congratulations ('to', 'Eric')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric', 'amp', ';']\n",
      "Eric ('amp', ';')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric', 'amp', ';', 'Lara', 'on']\n",
      "; ('Lara', 'on')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric', 'amp', ';', 'Lara', 'on', 'the', 'birth']\n",
      "on ('the', 'birth')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric', 'amp', ';', 'Lara', 'on', 'the', 'birth', 'of', 'their']\n",
      "birth ('of', 'their')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric', 'amp', ';', 'Lara', 'on', 'the', 'birth', 'of', 'their', 'son', ',']\n",
      "their ('son', ',')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric', 'amp', ';', 'Lara', 'on', 'the', 'birth', 'of', 'their', 'son', ',', 'Eric', 'Luke']\n",
      ", ('Eric', 'Luke')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric', 'amp', ';', 'Lara', 'on', 'the', 'birth', 'of', 'their', 'son', ',', 'Eric', 'Luke', 'Trump', 'this']\n",
      "Luke ('Trump', 'this')\n",
      "['We', 'pledge', 'our', 'solidarity', 'with', 'France', 'against', 'terror', '.', 'It', 'was', 'a', 'great', 'honor', 'to', 'welcome', 'Prime', 'Minister', 'Najib', 'Abdul', 'Razak', 'of', 'Malaysia', 'and', 'his', 'distinguished', 'delegation', 'to', 'th', 'Congratulations', 'to', 'Eric', 'amp', ';', 'Lara', 'on', 'the', 'birth', 'of', 'their', 'son', ',', 'Eric', 'Luke', 'Trump', 'this', 'morning', '!']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We pledge our solidarity with France against terror . It was a great honor to welcome Prime Minister Najib Abdul Razak of Malaysia and his distinguished delegation to th Congratulations to Eric amp ; Lara on the birth of their son , Eric Luke Trump this morning !'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_using_nxmgrams(3,2,trump_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
